# 랜덤 포레스트 (분류) 모델 예시코드
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# 예제 데이터 생성
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 탐색할 하이퍼파라미터 설정
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [10, 20, 30],
    'min_samples_leaf': [1, 2, 4],
    }

# GridSearchCV 객체 생성 (여기서 RandomForestClassifier 정의)
grid_search = GridSearchCV(estimator=RandomForestClassifier(),
                           param_grid=param_grid,
                           cv=5,
                           scoring='accuracy',
                           n_jobs=-1)

# 그리드 서치 수행
grid_search.fit(X_train, y_train)

# 최적의 하이퍼파라미터 출력
print("최적 하이퍼파라미터:", grid_search.best_params_)

# 최적의 모델
best_rf = grid_search.best_estimator_

# 테스트 데이터에 대해 예측
y_pred = best_rf.predict(X_test)

# 정확도 출력
print("테스트 정확도:", accuracy_score(y_test, y_pred))


-------------------------------------------------------------------------------
# 랜덤 포레스트 (회귀) 모델 예시코드

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_regression
from sklearn.metrics import mean_squared_error, make_scorer

# 예제 데이터 생성
X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)

# RandomForestRegressor 객체 생성
rf_regressor = RandomForestRegressor(random_state=42)

# 탐색할 하이퍼파라미터 설정
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

# GridSearchCV 객체 생성
grid_search = GridSearchCV(estimator=rf_regressor,
                           param_grid=param_grid,
                           scoring='neg_mean_squared_error',  # 평가 지표 (음수 MSE)
                           cv=5,
                           n_jobs=-1)

# 그리드 서치 수행
grid_search.fit(X, y)

# 최적의 하이퍼파라미터와 최적의 점수 출력
print("최적 하이퍼파라미터:", grid_search.best_params_)
print("최적 점수 (음수 MSE):", grid_search.best_score_)

# 최적의 모델
best_rf_regressor = grid_search.best_estimator_

# 추가적인 평가
y_pred = best_rf_regressor.predict(X)
mse = mean_squared_error(y, y_pred)
print("테스트 MSE:", mse)
print("테스트 RMSE:", np.sqrt(mse))


(랜덤 포레스트 모델의 주요 하이퍼파라미터는 다음과 같습니다)
:

n_estimators: 포레스트 안의 트리 수
max_depth: 각 트리의 최대 깊이
min_samples_split: 내부 노드를 분할하기 위한 최소 샘플 수
min_samples_leaf: 리프 노드에 필요한 최소 샘플 수
max_features: 각 트리에서 분할에 사용할 최대 특성 수
bootstrap: 샘플을 복원 추출할지 여부

----------------------------------------------------------------------------------
